# VERSION 1.8.2rc1
# AUTHOR: Mingxiang Zhang
# DESCRIPTION: Docker image to run Airflow on Kubernetes which is capable of creating Kubernetes jobs
# BUILD: docker build --rm -t ming-cho/kube-airflow:1.8.2rc1 .
# SOURCE: https://github.com/ming-cho/kube-airflow

FROM python:3.6-stretch
MAINTAINER Mingxiang Zhang <m.cho@opt.ne.jp>

# Never prompts the user for choices on installation/configuration of packages
ENV DEBIAN_FRONTEND noninteractive
ENV TERM linux

# Airflow
ARG AIRFLOW_VERSION=%%AIRFLOW_VERSION%%
ENV AIRFLOW_HOME /usr/local/airflow

# Define en_US.
ENV LANGUAGE en_US.UTF-8
ENV LANG en_US.UTF-8
ENV LC_ALL en_US.UTF-8
ENV LC_CTYPE en_US.UTF-8
ENV LC_MESSAGES en_US.UTF-8
ENV LC_ALL en_US.UTF-8

RUN apt-get update
RUN apt-get install -y --no-install-recommends apt-utils
RUN apt-get install -y --no-install-recommends python3-dev libkrb5-dev libsasl2-dev libssl-dev libffi-dev build-essential libblas-dev liblapack-dev libpq-dev git
RUN apt-get install -y --no-install-recommends python3-pip python-requests curl netcat locales vim

RUN sed -i 's/^# en_US.UTF-8 UTF-8$/en_US.UTF-8 UTF-8/g' /etc/locale.gen
RUN locale-gen
RUN update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8
RUN useradd -ms /bin/bash -d ${AIRFLOW_HOME} airflow

# Airflow tools for bash commands
RUN apt-get install -y --no-install-recommends rsync openssh-client sshpass

RUN apt-get clean
RUN rm -rf \
        /var/lib/apt/lists/* \
        /tmp/* \
        /var/tmp/* \
        /usr/share/man \
        /usr/share/doc \
        /usr/share/doc-base

ENV KUBECTL_VERSION %%KUBECTL_VERSION%%
RUN curl -L -o /usr/local/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v${KUBECTL_VERSION}/bin/linux/amd64/kubectl && chmod +x /usr/local/bin/kubectl

RUN pip install Cython pytz pyOpenSSL ndg-httpsclient pyasn1 flask_bcrypt
#RUN pip install apache-airflow[crypto,celery,postgres,hive,hdfs,jdbc,gcp_api]==$AIRFLOW_VERSION
RUN pip install "git+https://github.com/apache/incubator-airflow.git@${AIRFLOW_VERSION}#egg=apache-airflow[crypto,celery,postgres,hive,hdfs,jdbc,gcp_api]"
RUN pip install celery[redis]
RUN pip install google-cloud-bigquery slackweb

# init scripts
COPY script/entrypoint.sh /entrypoint.sh
COPY script/init_meta_db.py /init_meta_db.py
COPY config/airflow.cfg ${AIRFLOW_HOME}/airflow.cfg
# google cloud platform credential key
COPY gcp-airflow.json ${AIRFLOW_HOME}/gcp-airflow.json

ADD  instance /instance
ADD  dags ${AIRFLOW_HOME}/dags
ADD  plugins ${AIRFLOW_HOME}/plugins

RUN chmod +x /entrypoint.sh
RUN chown -R airflow: ${AIRFLOW_HOME}

# 8793 worker logs, 5555 flower, 8080 web
EXPOSE 8080 5555 8793

USER airflow
WORKDIR ${AIRFLOW_HOME}
ENTRYPOINT ["/entrypoint.sh"]
